# TuringDiffusion

Note that this implementation follows the original paper by Diederik Kingma and Max Welling "Auto-Regressive Flow Models" (https://arxiv.org/pdf/1605.09012.pdf) for the 'original' version of NCSSF, as well as the improvements suggested by Salimans et al. In their paper "Improving Normalizing Flows with a New Gradient Estimation Technique" (https://arxiv.org/abs/1711.05993). Finally, I added my own interpretation of the Neural Cumulative Standard Normalizing Flow proposed by Song et al. ("Neural Cumulative Standard Normalising Flows", https://arxiv.org/abs/2005.12212) which has some similarities but also notable differences compared to previous approaches. You can switch between these three variants using the self.ncsn_type attribute. Note that the 'ncsnf' version is significantly slower than the others due to its more complex formulas involving erf and erfc functions, so use it sparingly!

To use this network, simply instantiate it like any other PyTorch module, then call its forward method passing in a batch of inputs. It will return four outputs: the mean values of the denoised images (mu), the determinant of the Jacobian matrix used during decoding (logdetJ), the total training loss (loss), and the learned variance scales (sigma).

The forward function takes in two arguments, x representing the input image tensor and q_beta representing the latent space distribution means estimated from the encoder. The function first calculates the mean values of the input images, x, through a multiplication operation called gamma, followed by another multiplication operation called beta. These operations are performed element-wise across the batch dimensions, and they are computed based on the output of the q_net and p_net. Here's how:

gamma = self.q_net(z) # z represents the latent representation after encoding. The q_net layer here learns the mean of the gamma distributions.
p_beta, p_gamma = self.p_net(x, q_beta) # x represents the input image tensor. The p_net takes both the input image and the encoded mean as inputs to estimate the parameters of the gamma and beta distributions.
Next, the function combines the newly calculated gamma and beta values to obtain the denoised mean values, mu, which are the predicted mean values of the input images under the modeled distribution:

mu = p_gamma * x + p_beta * (1 - q_gamma) * q_beta + (1 - p_gamma) * x
After computing the denoised mean values, the function proceeds to calculate the variance scale, represented by sigma, which is an important factor in determining the width of the tails of the modeled distribution around the denoised mean values. This step involves estimating the Kullback-Leibler divergence (KLD) term between the current and initial distributions, which helps in improving the flow density estimation. There are different ways to compute the variance scale, depending on the variant of NCSN being implemented; in this case, we provide three options: 'original', 'improved', and 'ncsnf'.

Finally, the function computes the loss metric, which is the summation of several terms, including the logarithmic determinant J of the Jacobian matrix computed during decoding, the weighting factors specified by lambda_l and lambda_g, and the negative average log standard deviation, among others.

In summary, the forward function returns four quantities: mu, logdetJ, loss, and sigma, which represent the denoised mean values, logarithmic determinant of the Jacobian matrix, total training loss, and learned variance scales, respectively. To train or evaluate the GAN model, one would typically backpropagate through this function, updating the weights of the neural networks accordingly. By doing so repeatedly over multiple iterations, the model should converge to approximate the true joint probability distribution of the data.
