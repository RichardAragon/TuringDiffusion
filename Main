class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)
        
        self.fc1 = nn.Linear(in_features=int(np.prod([64, img_height // 2, img_width // 2])), 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.relu2 = nn.ReLU()
        
        self.fc2 = nn.Linear(in_features=512, int(img_height * img_width))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)
        x = self.maxpool1(x)
        
        x = torch.flatten(x, start_dim=-2)
        x = self.fc1(x)
        x = self.bn2(x)
        x = self.relu2(x)
        
        return self.sigmoid(self.fc2(x)).reshape((batch_size, img_height, img_width))

        class ACLayer(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(dim))
        self.beta = nn.Parameter(torch.zeros(dim))
        self.register_buffer('scale', torch.eye(dim))

    def forward(self, x):
        y = x * self.scale[:, :, None] + self.beta[None, ...]
        y = y / self.gamma[None, ...]
        self.scale[:, :, -1] *= x.shape[-1] ** (-0.5)
        return y

class QNet(nn.Module):
    def __init__(self, input_dim, hidden_dims=[256], num_layers=8):
        super().__init__()
        self.acls = nn.Sequential(*[ACLayer(input_dim + hidden_dims[i]), i in range(num_layers)] + [nn.Identity()] * (num_layers - len(hidden_dims)))
        self.fc1 = nn.Linear(input_dim + sum(hidden_dims), hidden_dims[0])
        self.act1 = nn.GELU()
        self.fc

class QNet(nn.Module):
    def __init__(self, input_dim, hidden_dims=[256], num_layers=8):
        super().__init__()
        self.acls = nn.Sequential(*[ACLayer(input_dim + hidden_dims[i]), i in range(num_layers)] + [nn.Identity()] * (num_layers - len(hidden_dims)))
        self.fc1 = nn.Linear(input_dim + sum(hidden_dims), hidden_dims[0])
        self.act1 = nn.GELU()
        self.fc2 = nn.Linear(hidden_dims[-1], input_dim)
        self.act2 = nn.Softplus()
        self.reset_parameters()

    def reset_parameters(self):
        # Initialize weights with orthogonal initialization
        for m in self._modules.values():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight)
            elif isinstance(m, ACLayer):
                m.gamma.data.fill_(1.)

    def forward(self, x, prev_z):
        out = self.acls(torch.cat([x, prev_z], axis=-1))
        h = self.fc1(out)
        h = self.act1(h)
        gamma = self.fc2(h).exp()
        beta = prev_z - gamma * x
        return beta, gamma

class PNet(nn.Module):
    def __init__(self, input_dim, hidden_dims=[256], num_layers=8):
        super().__init__()
        self.acls = nn.Sequential(*[ACLayer(input_dim + hidden_dims[i]), i in range(num_layers)] + [nn.Identity()] * (num_layers - len(hidden_dims)))
        self.fc1 = nn.Linear(input_dim + sum(hidden_dims), hidden_dims[0])
        self.act1 = nn.GELU()
        self.fc2 = nn.Linear(hidden_dims[-1], input_dim)
        self.act2 = nn.Softplus()
        self.reset_parameters()

    def reset_parameters(self):
        # Initialize weights with orthogonal initialization
        for m in self._modules.values():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight)
            elif isinstance(m, ACLayer):
                m.gamma.data.fill_(1.)

    def forward(self, x):
        out = self.acls(x)
        h = self.fc1(out)
        h = self.act1(h)
        gamma = self.fc2(h).exp()
        beta = torch.zeros_like(x)
        return beta, gamma

class NCSNF(nn.Module):
    """
    The neural cumulative standard normalizing flow model
    
    Input: batch of images (BxCxHxW)
    Output: denoised images (BxCxHxW)
    """
    def __init__(self, ncsn_type='ncsnf'):
        super().__init__()
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.encoder = Encoder(img_channels=3, hidden_size=256, depth=8)
        self.q_net = QNet(latent_size=256, hidden_dims=[256], num_layers=8)
        self.p_net = PNet(latent_size=256, hidden_dims=[256], num_layers=8)
        self.logstd = nn.Parameter(-2., requires_grad=True)
        self.lambda_l = 10.
        self.lambda_g = 1.
        self.lambda_h = .5
        self.ncsn_type = ncsn_type

@staticmethod
def logsumexp(x):
    maxval, index = torch.max(x, dim=1, keepdim=True)
    return maxval + np.log(index.shape[0]).item() - np.log(torch.sum(torch.exp(x - maxval)).detach())

def forward(self, x):
    z, logdetJ = self.encode(x)
    q_beta, q_gamma = self.q_net(z)
    p_beta, p_gamma = self.p_net(x, q_beta)
    
    mu = p_gamma*x + p_beta*(1-q_gamma)*q_beta + (1-p_gamma)*x
    sigmasq = p_gamma**2 + (1-p_gamma)**2*(1-q_gamma)**2*q_betasq
    sigmasq += (1-p_gamma)**2*(1-q_gamma)*sigmasq
    
    if self.ncsn_type == 'original':
        sigma = ((sigmasq/(2*self.lambda_h))**0.5).exp()
        
    elif self.ncsn_type == 'improved':
        sigma = torch.clamp((sigmasq/(2*self.lambda_h))**.5, min=1e-4)
        
    elif self.ncsn_type == 'ncsnf':
        logsigma = (-self.lambda_h/2)*np.log(torch.abs(sigma) + 1e-7) \
                      - self.lambda_h/2*torch.erf(np.sqrt(-self.lambda_h)*(np.abs(sigma)+1e-7)/np.sqrt(2))\
                      - self.lambda_h/4*np.sign(sigma)*torch.erfc(np.sqrt(-self.lambda_h)*(np.abs(sigma)-1e-7)/np.sqrt(2))
        
        sigma = torch.exp(logsigma)
    
    rho = ((mu - q_beta)*(q_gamma - p_gamma) / (p_gamma*(1-q_gamma))).tanh()
    kld_term = (rho**2 + (1-p_gamma)**2*(1-q_gamma)^2)*q_betasq.mean()
    
    loss = (logdetJ + self.lambda_l*kld_term).mean() - self.logstd.mean() \
           + (self.lambda_g*sigma.mean()).square().mean()
    
    return mu, logdetJ, loss, sigma
